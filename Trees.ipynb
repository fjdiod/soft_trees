{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz = 10\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=bsz, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "batch_size=bsz, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    4     2     5     0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB4CAYAAADi1gmcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYbvdWwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb24aa0de80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "classes = list(range(10))\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf(nn.Module):\n",
    "    def __init__(self, i_size, o_size, h_size=128):\n",
    "        super(Leaf, self).__init__()\n",
    "        self.i2h = nn.Linear(i_size, h_size)\n",
    "        self.h2o = nn.Linear(h_size, o_size)\n",
    "        self.soft = nn.LogSoftmax(1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.is_leaf = True\n",
    "\n",
    "    def forward(self, features):\n",
    "        out = self.i2h(features)\n",
    "        out = self.relu(out)\n",
    "        out = self.h2o(out)\n",
    "        return self.soft(out)\n",
    "\n",
    "    def accum_probs(self, features, path_prob):\n",
    "        return [[path_prob, self.forward(features)]]\n",
    "\n",
    "class Node(nn.Module):\n",
    "    def __init__(self, i_size, o_size):\n",
    "        super(Node, self).__init__()\n",
    "        self.o_size = o_size\n",
    "        self.i_size = i_size\n",
    "        self.i2o = nn.Linear(i_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.is_leaf = False\n",
    "    \n",
    "    def build_tree(self, depth):\n",
    "        if depth < 0:\n",
    "            raise NotImplementedError\n",
    "        if depth - 1 > 0:\n",
    "            self.left = Node(self.i_size, self.o_size)\n",
    "            self.right = Node(self.i_size, self.o_size)\n",
    "            self.left.build_tree(depth - 1)\n",
    "            self.right.build_tree(depth - 1)\n",
    "        else:\n",
    "            self.left = Leaf(self.i_size, self.o_size)\n",
    "            self.right = Leaf(self.i_size, self.o_size)\n",
    "\n",
    "    def forward(self, features):\n",
    "        pr = self.prob_left(features)\n",
    "        return pr*self.left(features) + (1 - pr)*self.right(features)\n",
    "\n",
    "    def prob_left(self, features):\n",
    "        return self.sigmoid(self.i2o(features))\n",
    "\n",
    "    def accum_probs(self, features, path_prob):\n",
    "        res = []\n",
    "        p_l = self.sigmoid(self.i2o(features))\n",
    "        res_l = self.left.accum_probs(features, p_l*path_prob)\n",
    "        res_r = self.right.accum_probs(features, (1 - p_l)*path_prob)\n",
    "        res.extend(res_l)\n",
    "        res.extend(res_r)\n",
    "        return res\n",
    "\n",
    "def tree_loss(path_probs, y_true):\n",
    "    loss = 0\n",
    "    criterion = nn.NLLLoss()\n",
    "    for p, pred in path_probs:\n",
    "        loss += p*criterion(pred, y_true)\n",
    "    return loss.mean()\n",
    "\n",
    "def tree_logloss(path_probs, y_true):\n",
    "    \"\"\"\n",
    "    Original loss from paper\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    criterion = nn.NLLLoss()\n",
    "    for p, pred in path_probs:\n",
    "        loss -= p*criterion(pred, y_true)\n",
    "    return -torch.log(loss.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Node(28*28, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.build_tree(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.04448346048593521 0.00022241730242967606\n",
      "1.02219557762146 0.08888920063320256\n",
      "1.451016902923584 0.08958627382096893\n",
      "0.7898892164230347 0.07377105898632635\n",
      "0.8192051649093628 0.09002668988283404\n",
      "1.0244543552398682 0.09055522648563055\n",
      "0.8202686309814453 0.06427575424821043\n",
      "1.0864510536193848 0.06934745590515376\n",
      "1.038622498512268 0.08273247984929184\n",
      "0.9751286506652832 0.08803182879798442\n",
      "0.8449207544326782 0.09709214693728882\n",
      "1.6900041103363037 0.07923221594566712\n",
      "1\n",
      "1.117004632949829 0.09148552033993837\n",
      "1.0373001098632812 0.053492266329180894\n",
      "0.9193560481071472 0.06770165810565232\n",
      "0.9085773229598999 0.07426115564112024\n",
      "0.9426153898239136 0.060279333355249494\n",
      "1.581984281539917 0.07996730690209006\n",
      "0.8262917399406433 0.04464407770685796\n",
      "1.4186687469482422 0.08468332829243082\n",
      "1.0184742212295532 0.06022437862151492\n",
      "1.783700704574585 0.07072012345957773\n",
      "1.1958775520324707 0.05676366136369324\n",
      "1.0159505605697632 0.08166369924033007\n",
      "2\n",
      "1.3204072713851929 0.08106961273033335\n",
      "1.20656418800354 0.054273743950489006\n",
      "1.2001416683197021 0.05138382116654611\n",
      "1.5498477220535278 0.08180975164873189\n",
      "0.5664224624633789 0.051097978407015035\n",
      "1.0965118408203125 0.05959568309531647\n",
      "1.313328504562378 0.053554794553404006\n",
      "0.8663555979728699 0.05170216243136792\n",
      "2.050429105758667 0.08129587434781911\n",
      "0.9895069003105164 0.06279321925190402\n",
      "1.0365841388702393 0.09404437325707476\n",
      "0.8960312008857727 0.05690750402854064\n",
      "3\n",
      "1.4265471696853638 0.06668195053788623\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-216-e2e54b9f2c35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccum_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mall_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(net.parameters())\n",
    "all_loss = np.zeros(200)\n",
    "criterion = nn.NLLLoss()\n",
    "for epoch in range(5):\n",
    "    print(epoch)\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        features, targets = batch\n",
    "        features = Variable(features.view(-1, 28*28))\n",
    "        targets = Variable(targets)\n",
    "        #out = net(features)\n",
    "        loss = tree_loss(net.accum_probs(features, 1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        all_loss[i%200] = loss.data[0]\n",
    "        if i % 500 == 0:\n",
    "            print(all_loss.max(), all_loss.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2.337132692337036 0.01168566346168518\n",
      "2.3393688201904297 0.70941203083843\n",
      "1.3418190479278564 0.3813070855103433\n",
      "1.240387201309204 0.353357810145244\n",
      "1.5959804058074951 0.31500955848023293\n",
      "1.2646723985671997 0.2582339872000739\n",
      "1.3248506784439087 0.2482780652702786\n",
      "1.549913763999939 0.2536597382789478\n",
      "1.1887271404266357 0.25024431850295514\n",
      "1.5904780626296997 0.2372973468201235\n",
      "1.4080578088760376 0.2245685329241678\n",
      "1.1917880773544312 0.20229555137222632\n",
      "1.4389848709106445 0.20757214635959825\n",
      "1.5717592239379883 0.19943377160350792\n",
      "1.2524627447128296 0.19819177539437077\n",
      "1.2399612665176392 0.17059512886451558\n",
      "1.3004764318466187 0.1951107891072752\n",
      "1.2526800632476807 0.17038131895358674\n",
      "1.405723214149475 0.16615860196354335\n",
      "1.120182991027832 0.19178391175126308\n",
      "1.256012201309204 0.16591066210065036\n",
      "1.600950002670288 0.173624066633638\n",
      "1.495044231414795 0.14647242508857744\n",
      "1.1515161991119385 0.15268506557506042\n",
      "1.668564796447754 0.15179500662139617\n",
      "0.9392849802970886 0.13501581214077304\n",
      "0.994438648223877 0.14582072310411603\n",
      "1.3024874925613403 0.16812489391770213\n",
      "1.2526028156280518 0.16104403021628969\n",
      "2.090782642364502 0.15498800041357755\n",
      "1\n",
      "2.249655246734619 0.17349214131652843\n",
      "1.0166481733322144 0.11070077896758448\n",
      "1.1756541728973389 0.11778788677183911\n",
      "0.7878836393356323 0.1049861797504127\n",
      "1.190197229385376 0.10084869241138222\n",
      "0.8199559450149536 0.12384143023067735\n",
      "1.2783963680267334 0.10229497142849141\n",
      "1.1938849687576294 0.11119598269142443\n",
      "0.9072431325912476 0.11310906508471817\n",
      "1.49693763256073 0.11220718260694412\n",
      "1.5392417907714844 0.13216923019790555\n",
      "1.3014624118804932 0.09925999975246669\n",
      "1.3958823680877686 0.13049017116543837\n",
      "0.8362331390380859 0.11192860983122956\n",
      "1.2022597789764404 0.10416906210994056\n",
      "1.4045004844665527 0.1321995350914949\n",
      "0.9872671365737915 0.10715923404830391\n",
      "1.2150428295135498 0.12070791431877297\n",
      "0.7070863842964172 0.08775358264509123\n",
      "0.9247279167175293 0.11101535839035932\n",
      "1.7719978094100952 0.10617282761540991\n",
      "1.2982298135757446 0.11290516461915104\n",
      "1.0412086248397827 0.11625058454450482\n",
      "1.1608940362930298 0.10263639220320328\n",
      "1.4126402139663696 0.12701430193090346\n",
      "0.9020196795463562 0.1238744110269181\n",
      "0.9309577941894531 0.10307445798127446\n",
      "1.4845507144927979 0.09216137280731346\n",
      "1.2667077779769897 0.1063583835123427\n",
      "0.9360715746879578 0.1067571297995164\n",
      "2\n",
      "1.610906958580017 0.13621546054797362\n",
      "1.3921765089035034 0.08986252051625343\n",
      "0.9303730130195618 0.08107140277428698\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-246-72f4dd786c77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mall_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(net.parameters())\n",
    "all_loss = np.zeros(200)\n",
    "criterion = nn.NLLLoss()\n",
    "for epoch in range(5):\n",
    "    print(epoch)\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        features, targets = batch\n",
    "        features = Variable(features.view(-1, 28*28))\n",
    "        targets = Variable(targets)\n",
    "        out = net(features)\n",
    "        loss = criterion(out, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        all_loss[i%200] = loss.data[0]\n",
    "        if i % 200 == 0:\n",
    "            print(all_loss.max(), all_loss.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "nan nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-266-0f18e63191e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#out = net(features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_logloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccum_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mall_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(net.parameters())\n",
    "all_loss = np.zeros(200)\n",
    "criterion = nn.NLLLoss()\n",
    "for epoch in range(5):\n",
    "    print(epoch)\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        features, targets = batch\n",
    "        features = Variable(features.view(-1, 28*28))\n",
    "        targets = Variable(targets)\n",
    "        #out = net(features)\n",
    "        loss = tree_logloss(net.accum_probs(features, 1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        all_loss[i%200] = loss.data[0]\n",
    "        if i % 500 == 0:\n",
    "            print(all_loss.max(), all_loss.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "total = 0\n",
    "correct = 0\n",
    "for data in test_loader:\n",
    "    images, labels = data\n",
    "    features = Variable(images.view(-1, 28*28))\n",
    "    targets = Variable(labels)\n",
    "    outputs = net(features)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == targets.data).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9594"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB4CAYAAADi1gmcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb2441c6390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for data in test_loader:\n",
    "    images, labels = data\n",
    "    features = Variable(images.view(-1, 28*28))\n",
    "    break\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    0\n",
       "    6\n",
       "    0\n",
       "    2\n",
       "    1\n",
       "    7\n",
       "    0\n",
       "    0\n",
       "    5\n",
       "    0\n",
       "[torch.LongTensor of size 10x1]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(features).topk(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Variable containing:\n",
       "   0.3698\n",
       "   0.2354\n",
       "   0.4157\n",
       "   0.3729\n",
       "   0.2251\n",
       "   0.2064\n",
       "   0.4087\n",
       "   0.2474\n",
       "   0.2635\n",
       "   0.4449\n",
       "  [torch.FloatTensor of size 10x1], Variable containing:\n",
       "  -2.3399 -2.1639 -2.3609 -2.2783 -2.1904 -2.4916 -2.0536 -2.3836 -2.4639 -2.3885\n",
       "  -2.1216 -2.4151 -2.4126 -2.6590 -1.6693 -2.6165 -2.2584 -2.4090 -2.7313 -2.2054\n",
       "  -2.4880 -2.4315 -2.4022 -2.4181 -1.8086 -2.3845 -2.6030 -2.5302 -2.6341 -1.7844\n",
       "  -2.0468 -2.6011 -2.1479 -2.4624 -1.6819 -2.7388 -2.4847 -2.4772 -2.7785 -2.1664\n",
       "  -2.3826 -2.1342 -2.5188 -2.6239 -1.7700 -2.5679 -2.3595 -2.4636 -2.3183 -2.1962\n",
       "  -2.3078 -2.1739 -2.2567 -2.5060 -2.0410 -2.2095 -2.4665 -2.6322 -2.4764 -2.1204\n",
       "  -2.3445 -2.3085 -2.1451 -2.3394 -2.0232 -2.3128 -2.3955 -2.4376 -2.6927 -2.1730\n",
       "  -2.2243 -2.3504 -2.1915 -2.2503 -2.1237 -2.3369 -2.4652 -2.4607 -2.5458 -2.1678\n",
       "  -2.1088 -2.3997 -2.3813 -2.4653 -1.7977 -2.5648 -2.4795 -2.3994 -2.4307 -2.2508\n",
       "  -2.2055 -2.3440 -2.4924 -2.2513 -1.9905 -2.3058 -2.5462 -2.3740 -2.7144 -2.0262\n",
       "  [torch.FloatTensor of size 10x10]], [Variable containing:\n",
       "   0.2023\n",
       "   0.1906\n",
       "   0.1621\n",
       "   0.2027\n",
       "   0.1740\n",
       "   0.1510\n",
       "   0.1896\n",
       "   0.2189\n",
       "   0.1629\n",
       "   0.2151\n",
       "  [torch.FloatTensor of size 10x1], Variable containing:\n",
       "  -2.2569 -2.5454 -2.5742 -2.3005 -2.1076 -2.5349 -2.1206 -2.7611 -1.9849 -2.1279\n",
       "  -2.4451 -2.6875 -2.3200 -2.3655 -2.1850 -2.1116 -2.2056 -2.9604 -2.6360 -1.6825\n",
       "  -2.3834 -2.6501 -2.3430 -2.7408 -2.0373 -2.2899 -1.9419 -2.5356 -2.3370 -2.0744\n",
       "  -2.4487 -2.3131 -2.2839 -2.4450 -1.9862 -2.4141 -2.3860 -2.5837 -2.3289 -2.0064\n",
       "  -2.2261 -2.3297 -2.4047 -2.5586 -1.8194 -2.6201 -2.3084 -2.5271 -2.3853 -2.1143\n",
       "  -2.1807 -2.3491 -2.3505 -2.7096 -1.8642 -2.5442 -2.2515 -2.9250 -2.2278 -2.0442\n",
       "  -2.6483 -2.6981 -2.3016 -2.0978 -2.2082 -2.0539 -2.2294 -2.7597 -2.4333 -1.9499\n",
       "  -2.2478 -2.2413 -2.4525 -2.5767 -2.0437 -2.4021 -2.3375 -2.4862 -2.2122 -2.1488\n",
       "  -2.4977 -2.5281 -2.4488 -2.2869 -2.1380 -2.2083 -1.8268 -3.1076 -2.3182 -2.1365\n",
       "  -2.4699 -2.7363 -2.6291 -2.4751 -2.0599 -2.2217 -2.0199 -2.6189 -2.3804 -1.8304\n",
       "  [torch.FloatTensor of size 10x10]], [Variable containing:\n",
       "   0.1500\n",
       "   0.3105\n",
       "   0.2761\n",
       "   0.2324\n",
       "   0.2885\n",
       "   0.3726\n",
       "   0.1900\n",
       "   0.2491\n",
       "   0.3863\n",
       "   0.2082\n",
       "  [torch.FloatTensor of size 10x1], Variable containing:\n",
       "  -2.4817 -2.3642 -2.1983 -1.9154 -2.3731 -2.7804 -2.2032 -2.2981 -2.0585 -2.6541\n",
       "  -2.2064 -2.4536 -2.2016 -2.3988 -2.6483 -2.4926 -2.2052 -2.0613 -1.9969 -2.5804\n",
       "  -2.3893 -2.3988 -2.2491 -2.2453 -2.7599 -2.7506 -2.4298 -2.0722 -1.8780 -2.1888\n",
       "  -2.0625 -2.3683 -2.3006 -2.3478 -2.4261 -2.5231 -2.3741 -2.1183 -2.1168 -2.5119\n",
       "  -2.1519 -2.4635 -2.1356 -2.4990 -2.5157 -2.7174 -2.1439 -2.1402 -2.0791 -2.3911\n",
       "  -2.1935 -2.4856 -2.1152 -2.3038 -2.6395 -2.2836 -2.3762 -2.1854 -2.1379 -2.4285\n",
       "  -2.5971 -2.3147 -2.3334 -2.3930 -2.8668 -2.2828 -2.2946 -1.8863 -2.2348 -2.1196\n",
       "  -2.2864 -2.5329 -2.0351 -2.3958 -2.5697 -2.4568 -2.3227 -2.2779 -2.1953 -2.0951\n",
       "  -2.0718 -2.4249 -2.0082 -2.2583 -2.6010 -2.4901 -2.2718 -2.2870 -2.2867 -2.4840\n",
       "  -2.3552 -2.3983 -2.4342 -2.0001 -2.7633 -2.2410 -2.2048 -2.1984 -2.0981 -2.5525\n",
       "  [torch.FloatTensor of size 10x10]], [Variable containing:\n",
       "   0.2779\n",
       "   0.2635\n",
       "   0.1462\n",
       "   0.1921\n",
       "   0.3125\n",
       "   0.2700\n",
       "   0.2118\n",
       "   0.2846\n",
       "   0.1874\n",
       "   0.1318\n",
       "  [torch.FloatTensor of size 10x1], Variable containing:\n",
       "  -2.0202 -2.7773 -2.2261 -3.0488 -2.0712 -2.1249 -2.8210 -2.3672 -2.6582 -1.7096\n",
       "  -2.2793 -2.5752 -2.2229 -2.5985 -1.9750 -2.0436 -2.6261 -2.2669 -2.6588 -2.0836\n",
       "  -2.4425 -2.5047 -2.0331 -3.1652 -1.9747 -2.3755 -2.9745 -2.3336 -2.3832 -1.6812\n",
       "  -2.3871 -2.4521 -2.1144 -2.6191 -2.0074 -2.0013 -2.8200 -2.4763 -2.4886 -2.0231\n",
       "  -2.2924 -2.8884 -1.9500 -2.8363 -2.3087 -2.3323 -2.6735 -2.1520 -2.1936 -1.9028\n",
       "  -2.1175 -2.9577 -2.2281 -2.8066 -2.3852 -2.4515 -2.2564 -2.1483 -2.1329 -1.9558\n",
       "  -2.3571 -2.5275 -1.9558 -2.5176 -2.2382 -1.9458 -2.5646 -2.4793 -2.6922 -2.0768\n",
       "  -1.9875 -2.6472 -2.1512 -2.6528 -2.2528 -2.2752 -2.2276 -2.3790 -2.5602 -2.1226\n",
       "  -2.2645 -2.6293 -2.2626 -2.8512 -2.1600 -2.1147 -2.4079 -2.2015 -2.5672 -1.9054\n",
       "  -2.5309 -2.1781 -1.7692 -2.5671 -2.4131 -2.2603 -2.6826 -2.6715 -2.5922 -1.8729\n",
       "  [torch.FloatTensor of size 10x10]]]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.accum_probs(features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.5197  0.4803\n",
       "[torch.FloatTensor of size 1x2]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.4803\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(p[0][1], t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l = Leaf(20, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.7010  0.2990\n",
       " 0.4587  0.5413\n",
       " 0.6445  0.3555\n",
       " 0.6523  0.3477\n",
       " 0.5520  0.4480\n",
       " 0.5729  0.4271\n",
       " 0.4309  0.5691\n",
       " 0.6113  0.3887\n",
       " 0.5364  0.4636\n",
       " 0.4727  0.5273\n",
       " 0.5744  0.4256\n",
       " 0.4254  0.5746\n",
       " 0.6120  0.3880\n",
       " 0.3881  0.6119\n",
       " 0.4329  0.5671\n",
       " 0.6215  0.3785\n",
       " 0.5566  0.4434\n",
       " 0.4899  0.5101\n",
       " 0.5596  0.4404\n",
       " 0.4213  0.5787\n",
       " 0.5454  0.4546\n",
       " 0.6407  0.3593\n",
       " 0.7366  0.2634\n",
       " 0.5357  0.4643\n",
       " 0.4664  0.5336\n",
       " 0.4837  0.5163\n",
       " 0.4695  0.5305\n",
       " 0.3931  0.6069\n",
       " 0.4598  0.5402\n",
       " 0.5820  0.4180\n",
       " 0.5449  0.4551\n",
       " 0.5599  0.4401\n",
       " 0.5203  0.4797\n",
       " 0.4539  0.5461\n",
       " 0.4069  0.5931\n",
       " 0.4765  0.5235\n",
       " 0.6093  0.3907\n",
       " 0.5651  0.4349\n",
       " 0.5195  0.4805\n",
       " 0.7444  0.2556\n",
       " 0.4269  0.5731\n",
       " 0.4473  0.5527\n",
       " 0.5124  0.4876\n",
       " 0.4995  0.5005\n",
       " 0.7357  0.2643\n",
       " 0.5297  0.4703\n",
       " 0.5353  0.4647\n",
       " 0.5564  0.4436\n",
       " 0.4799  0.5201\n",
       " 0.4594  0.5406\n",
       " 0.4223  0.5777\n",
       " 0.6069  0.3931\n",
       " 0.5184  0.4816\n",
       " 0.2934  0.7066\n",
       " 0.4795  0.5205\n",
       " 0.4228  0.5772\n",
       " 0.4746  0.5254\n",
       " 0.4543  0.5457\n",
       " 0.4915  0.5085\n",
       " 0.7506  0.2494\n",
       " 0.3913  0.6087\n",
       " 0.5906  0.4094\n",
       " 0.6700  0.3300\n",
       " 0.4345  0.5655\n",
       " 0.4025  0.5975\n",
       " 0.5730  0.4270\n",
       " 0.4163  0.5837\n",
       " 0.5017  0.4983\n",
       " 0.4581  0.5419\n",
       " 0.5740  0.4260\n",
       " 0.5664  0.4336\n",
       " 0.4470  0.5530\n",
       " 0.4716  0.5284\n",
       " 0.4761  0.5239\n",
       " 0.4448  0.5552\n",
       " 0.5357  0.4643\n",
       " 0.4385  0.5615\n",
       " 0.5305  0.4695\n",
       " 0.5145  0.4855\n",
       " 0.5347  0.4653\n",
       " 0.4728  0.5272\n",
       " 0.4666  0.5334\n",
       " 0.3363  0.6637\n",
       " 0.6276  0.3724\n",
       " 0.4739  0.5261\n",
       " 0.5521  0.4479\n",
       " 0.5093  0.4907\n",
       " 0.4782  0.5218\n",
       " 0.5116  0.4884\n",
       " 0.5564  0.4436\n",
       " 0.4297  0.5703\n",
       " 0.3842  0.6158\n",
       " 0.3599  0.6401\n",
       " 0.4299  0.5701\n",
       " 0.5588  0.4412\n",
       " 0.4090  0.5910\n",
       " 0.3622  0.6378\n",
       " 0.5353  0.4647\n",
       " 0.4537  0.5463\n",
       " 0.6025  0.3975\n",
       "[torch.FloatTensor of size 100x2]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 20])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.5568\n",
       " 0.4157\n",
       " 0.6472\n",
       " 0.5052\n",
       " 0.7840\n",
       " 0.5970\n",
       " 0.5989\n",
       " 0.6032\n",
       " 0.5259\n",
       " 0.4826\n",
       " 0.5710\n",
       " 0.3354\n",
       " 0.6097\n",
       " 0.2600\n",
       " 0.4450\n",
       " 0.4455\n",
       " 0.6031\n",
       " 0.4423\n",
       " 0.6174\n",
       " 0.5324\n",
       " 0.4664\n",
       " 0.6138\n",
       " 0.3941\n",
       " 0.4854\n",
       " 0.3821\n",
       " 0.5882\n",
       " 0.6332\n",
       " 0.6062\n",
       " 0.2798\n",
       " 0.4175\n",
       " 0.4970\n",
       " 0.4680\n",
       " 0.4224\n",
       " 0.5263\n",
       " 0.3459\n",
       " 0.3255\n",
       " 0.5238\n",
       " 0.5932\n",
       " 0.4105\n",
       " 0.5355\n",
       " 0.6300\n",
       " 0.5799\n",
       " 0.5868\n",
       " 0.6435\n",
       " 0.6820\n",
       " 0.3809\n",
       " 0.5247\n",
       " 0.5251\n",
       " 0.4482\n",
       " 0.5785\n",
       " 0.3621\n",
       " 0.5591\n",
       " 0.4758\n",
       " 0.3217\n",
       " 0.5141\n",
       " 0.3364\n",
       " 0.6387\n",
       " 0.6046\n",
       " 0.4159\n",
       " 0.6508\n",
       " 0.2434\n",
       " 0.4416\n",
       " 0.7236\n",
       " 0.2498\n",
       " 0.3928\n",
       " 0.5419\n",
       " 0.6580\n",
       " 0.4069\n",
       " 0.4864\n",
       " 0.5594\n",
       " 0.5003\n",
       " 0.4538\n",
       " 0.4237\n",
       " 0.4355\n",
       " 0.4910\n",
       " 0.4696\n",
       " 0.6194\n",
       " 0.6092\n",
       " 0.5075\n",
       " 0.5751\n",
       " 0.5980\n",
       " 0.5513\n",
       " 0.3349\n",
       " 0.5950\n",
       " 0.4625\n",
       " 0.4790\n",
       " 0.5537\n",
       " 0.3851\n",
       " 0.6574\n",
       " 0.5526\n",
       " 0.3472\n",
       " 0.4050\n",
       " 0.5815\n",
       " 0.3393\n",
       " 0.3553\n",
       " 0.2930\n",
       " 0.1914\n",
       " 0.4552\n",
       " 0.1965\n",
       " 0.5975\n",
       "[torch.FloatTensor of size 100x1]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
